name: lm eval on gemma-2b
debug: false
workspace: agnieszka
project: llm-blog3
environment:
  environment_variables:
    - NCCL_DEBUG=INFO
    - TRANSFORMERS_CACHE=/nvmefs1/agnieszka.ciborowska
    - HF_DATASETS_CACHE=/nvmefs1/agnieszka.ciborowska
    - HF_HOME=/nvmefs1/agnieszka.ciborowska
    - HF_MODULES_CACHE=/nvmefs1/agnieszka.ciborowska
  image: determinedai/environments:cuda-11.8-pytorch-2.0-gpu-95c7a14
resources:
  slots_per_trial: 1
  resource_pool: A100
  max_slots: 1
searcher:
  name: grid
  max_length:
    batches: 5000
  metric: eval_accuracy
  smaller_is_better: false
hyperparameters:
  model_args:
    hf_model_name: "google/gemma-2b"
    # model_ckpt: "29a191f1-f65b-48a7-a288-624b8b8203de" basic sft
    # model_ckpt: "f6352b17-787c-4375-bebe-8e0e64e3a656" completions sft
    # model_ckpt: "55d2f23a-2182-4cad-b8de-731727a20324"
    trust_remote_code: true
    use_accelerate: false
  batch_size: 4
  max_batch_size: 4
  task:
    type: categorical
    vals:
      - name: arc_challenge
        num_fewshot: 25
      - name: truthfulqa_mc
        num_fewshot: 0
      - name: hellaswag
        num_fewshot: 10
      - name: hendrycks*
        num_fewshot: 5
      - name: winogrande
        num_fewshot: 5
      - name: gsm8k
        num_fewshot: 5
  device: "cuda"
entrypoint: >-
  python run_lm_eval_harness.py
max_restarts: 0
bind_mounts:
  - container_path: /nvmefs1/agnieszka.ciborowska
    host_path: /nvmefs1/agnieszka.ciborowska
    propagation: rprivate
    read_only: false